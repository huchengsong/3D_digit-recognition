{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3D Hand-writting test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Numpy, TensorFlow, and MNIST data\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn.datasets.mnist as mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the training and test data\n",
    "trainX, trainY, testX, testY = mnist.load_data(one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Visualize the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Visualizing the data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def display_same_digit(digit,number):\n",
    "    collectionY = []\n",
    "    for i in range(0,len(trainY)):\n",
    "        if trainY[i][digit]==1:\n",
    "            collectionY.append(i)\n",
    "    collectionX = [trainX[i] for i in collectionY]\n",
    "    for j in range(number):\n",
    "        image = collectionX[j].reshape([28,28])\n",
    "        plt.title('Training data, Label: %d' % digit)\n",
    "        plt.imshow(image, cmap='gray_r')\n",
    "        plt.show()\n",
    "        \n",
    "display_same_digit(6,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Make 3d digit from 2d image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#convert training data\n",
    "\n",
    "def conv_2d_3d(digit_2d):\n",
    "    digit_3d=[]\n",
    "    for i in range(len(digit_2d)):\n",
    "        single_3d=np.zeros([28,28,28],dtype=np.bool_)\n",
    "        if i%500==0:\n",
    "            print(i)\n",
    "        for j in range(28):\n",
    "            for k in range(28):\n",
    "                depth =int(np.ceil(digit_2d[i][j][k]*4))\n",
    "                single_3d[j][k][14-depth:13+depth]=True\n",
    "        digit_3d.append(single_3d)\n",
    "    return digit_3d\n",
    "\n",
    "#converting testing data\n",
    "train_digit_2d = trainX.reshape([len(trainX),28,28])\n",
    "test_digit_2d = testX.reshape([len(testX),28,28])\n",
    "train_digit_3d=conv_2d_3d(train_digit_2d)\n",
    "test_digit_3d=conv_2d_3d(test_digit_2d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "np.save('train_digit_3d.out', train_digit_3d) \n",
    "np.save('test_digit_3d.out', test_digit_3d) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def show_2d(digit_2d, targets,index):\n",
    "    plt.title('Label: %d' % np.argmax(targets[index]))\n",
    "    plt.imshow(digit_2d[index], cmap='gray_r')\n",
    "    plt.show()\n",
    "show_2d(train_digit_2d, trainY, 2)\n",
    "\n",
    "def show_3d(digit_3d, targets,index):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    pos = np.where(digit_3d[index]==1)\n",
    "    ax.scatter(pos[0], pos[1], pos[2],c='black')\n",
    "    ax.set_xlabel('X Label')\n",
    "    ax.set_ylabel('Y Label')\n",
    "    ax.set_zlabel('Z Label')\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,27])\n",
    "    axes.set_ylim([0,27])\n",
    "    axes.set_zlim([0,27])\n",
    "    for angle in range(0, 360):\n",
    "        ax.view_init(60, angle)\n",
    "        plt.draw()\n",
    "        plt.pause(.001)\n",
    "\n",
    "show_3d(train_digit_3d, trainY, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49500\n"
     ]
    }
   ],
   "source": [
    "test_digit=np.load('test_digit_3d.out.npy')\n",
    "test_target=testY\n",
    "\n",
    "whole_digit=np.load('train_digit_3d.out.npy')\n",
    "divide=int(len(whole_digit)*0.9)\n",
    "whole_target=trainY\n",
    "train_digit=whole_digit[0:divide]\n",
    "train_target=whole_target[0:divide]\n",
    "valid_digit=whole_digit[divide+1:]\n",
    "valid_target=whole_target[divide+1:]\n",
    "print(len(train_digit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,shape=[None, image_shape[0], image_shape[1], image_shape[2],1],name = \"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,shape=[None, n_classes],name = \"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    keep_prob=tf.placeholder(tf.float32, name= \"keep_prob\" )\n",
    "    return keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv3d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 3-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 3-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 3-D Tuple for pool\n",
    "    :param pool_strides: Stride 3-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight = tf.Variable(tf.random_normal([conv_ksize[0], conv_ksize[1],conv_ksize[2], x_tensor.get_shape().as_list()[-1], conv_num_outputs],mean=0.0,stddev = 0.1)) \n",
    "    \n",
    "    conv_layer = tf.nn.conv3d(\n",
    "        x_tensor, \n",
    "        weight, \n",
    "        strides=[1, conv_strides[0], conv_strides[1],conv_strides[2], 1], \n",
    "        padding='SAME')    \n",
    "    \n",
    "    conv_layer = tf.nn.relu(conv_layer)                           \n",
    "    out=tf.nn.max_pool3d(\n",
    "        conv_layer,\n",
    "        ksize=[1, pool_ksize[0], pool_ksize[1], pool_ksize[2], 1],\n",
    "        strides=[1, pool_strides[0], pool_strides[1], pool_strides[2], 1],\n",
    "        padding='SAME')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape=x_tensor.get_shape().as_list()\n",
    "    return tf.reshape(x_tensor, [-1,shape[1]*shape[2]*shape[3]*shape[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape=x_tensor.get_shape().as_list()\n",
    "    weight = tf.Variable(tf.random_normal([shape[1],num_outputs],mean=0.0,stddev = 0.1))\n",
    "    bias = tf.Variable(tf.random_normal([num_outputs],mean=0.0,stddev = 0.1))\n",
    "    output = tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "    output = tf.nn.relu(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape=x_tensor.get_shape().as_list()\n",
    "    weight = tf.Variable(tf.random_normal([shape[1],num_outputs],mean=0.0,stddev = 0.1))\n",
    "    bias = tf.Variable(tf.random_normal([num_outputs],mean=0.0,stddev = 0.1))\n",
    "    output = tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv_num_outputs1=32\n",
    "    conv_num_outputs2=64\n",
    "    conv_ksize=[5,5,5]\n",
    "    conv_strides=[2,2,2]\n",
    "    pool_ksize=[2,2,2]\n",
    "    pool_strides=[2,2,2]\n",
    "    \n",
    "    conv1=conv3d_maxpool(x, conv_num_outputs1, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv2=conv3d_maxpool(conv1, conv_num_outputs2, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    ft=flatten(conv2)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    num_outputs1=64\n",
    "    num_outputs2=16\n",
    "    fc1=fully_conn(ft, num_outputs1)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "    fc2=fully_conn(fc1, num_outputs2)\n",
    "\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out=output(fc2, 10)\n",
    "    # TODO: return output\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((28, 28, 28, 1))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict = \n",
    "                   {x: feature_batch,y: label_batch, keep_prob: 1.0})\n",
    "    valid_digit2=np.expand_dims(valid_digit,4)\n",
    "    acc = session.run(accuracy,feed_dict = \n",
    "                  {x: valid_digit2[0:2048], y: valid_target[0:2048], keep_prob: 1.0})\n",
    "    print('Loss: {:>10.4f} Accuracy: {:.6f}'.format(loss,acc))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={\n",
    "                x: feature_batch,\n",
    "                y: label_batch,\n",
    "                keep_prob: keep_probability})\n",
    "\n",
    "def load_preprocess_training_batch(batch_id, batch_size):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    n_batches=len(test_digit)//batch_size\n",
    "    test_digit2=np.expand_dims(test_digit,4)\n",
    "    digits=[]\n",
    "    targets=[]\n",
    "    for i in range(n_batches):\n",
    "        digits.append(test_digit2[i*batch_size:(i+1)*batch_size])\n",
    "        targets.append(test_target[i*batch_size:(i+1)*batch_size])\n",
    "    digits2=np.array(digits)\n",
    "    targets2=np.array(targets)\n",
    "    return(digits2[batch_id],targets2[batch_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 99:  Loss:     0.7432 Accuracy: 0.752441\n",
      "Epoch  2, CIFAR-10 Batch 99:  Loss:     0.4526 Accuracy: 0.825195\n",
      "Epoch  3, CIFAR-10 Batch 99:  Loss:     0.3629 Accuracy: 0.898926\n",
      "Epoch 15, CIFAR-10 Batch 99:  Loss:     0.0096 Accuracy: 0.973633\n",
      "Epoch 16, CIFAR-10 Batch 99:  Loss:     0.0078 Accuracy: 0.968262\n",
      "Epoch 17, CIFAR-10 Batch 99:  Loss:     0.0122 Accuracy: 0.973633\n",
      "Epoch 18, CIFAR-10 Batch 99:  Loss:     0.0095 Accuracy: 0.967773\n",
      "Epoch 19, CIFAR-10 Batch 99:  Loss:     0.0086 Accuracy: 0.971191\n",
      "Epoch 20, CIFAR-10 Batch 99:  Loss:     0.0056 Accuracy: 0.969238\n",
      "Epoch 21, CIFAR-10 Batch 99:  Loss:     0.0134 Accuracy: 0.970215\n",
      "Epoch 22, CIFAR-10 Batch 99:  Loss:     0.0066 Accuracy: 0.971191\n",
      "Epoch 23, CIFAR-10 Batch 99:  Loss:     0.0047 Accuracy: 0.972656\n",
      "Epoch 36, CIFAR-10 Batch 99:  Loss:     0.0005 Accuracy: 0.975586\n",
      "Epoch 37, CIFAR-10 Batch 99:  Loss:     0.0003 Accuracy: 0.974609\n",
      "Epoch 38, CIFAR-10 Batch 99:  Loss:     0.0009 Accuracy: 0.972656\n",
      "Epoch 39, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.972656\n",
      "Epoch 40, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.971680\n",
      "Epoch 41, CIFAR-10 Batch 99:  Loss:     0.0014 Accuracy: 0.973145\n",
      "Epoch 42, CIFAR-10 Batch 99:  Loss:     0.0002 Accuracy: 0.973633\n",
      "Epoch 43, CIFAR-10 Batch 99:  Loss:     0.0006 Accuracy: 0.973633\n",
      "Epoch 44, CIFAR-10 Batch 99:  Loss:     0.0004 Accuracy: 0.977539\n",
      "Epoch 45, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.976074\n",
      "Epoch 46, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.973633\n",
      "Epoch 47, CIFAR-10 Batch 99:  Loss:     0.0004 Accuracy: 0.972168\n",
      "Epoch 48, CIFAR-10 Batch 99:  Loss:     0.0002 Accuracy: 0.972168\n",
      "Epoch 49, CIFAR-10 Batch 99:  Loss:     0.0012 Accuracy: 0.969727\n",
      "Epoch 50, CIFAR-10 Batch 99:  Loss:     0.0030 Accuracy: 0.974609\n",
      "Epoch 51, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.972656\n",
      "Epoch 52, CIFAR-10 Batch 99:  Loss:     0.0003 Accuracy: 0.972656\n",
      "Epoch 53, CIFAR-10 Batch 99:  Loss:     0.0002 Accuracy: 0.975098\n",
      "Epoch 54, CIFAR-10 Batch 99:  Loss:     0.0006 Accuracy: 0.976074\n",
      "Epoch 55, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.974609\n",
      "Epoch 56, CIFAR-10 Batch 99:  Loss:     0.0005 Accuracy: 0.977539\n",
      "Epoch 57, CIFAR-10 Batch 99:  Loss:     0.0002 Accuracy: 0.973145\n",
      "Epoch 58, CIFAR-10 Batch 99:  Loss:     0.0004 Accuracy: 0.972168\n",
      "Epoch 59, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.975586\n",
      "Epoch 60, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.973145\n",
      "Epoch 61, CIFAR-10 Batch 99:  Loss:     0.0002 Accuracy: 0.973633\n",
      "Epoch 62, CIFAR-10 Batch 99:  Loss:     0.0002 Accuracy: 0.974609\n",
      "Epoch 63, CIFAR-10 Batch 99:  Loss:     0.0000 Accuracy: 0.978516\n",
      "Epoch 64, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.978516\n",
      "Epoch 65, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.975586\n",
      "Epoch 66, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.976562\n",
      "Epoch 67, CIFAR-10 Batch 99:  Loss:     0.0004 Accuracy: 0.975098\n",
      "Epoch 68, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.978027\n",
      "Epoch 69, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.976562\n",
      "Epoch 70, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.976562\n",
      "Epoch 71, CIFAR-10 Batch 99:  Loss:     0.0000 Accuracy: 0.977051\n",
      "Epoch 72, CIFAR-10 Batch 99:  Loss:     0.0000 Accuracy: 0.975586\n",
      "Epoch 73, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.975098\n",
      "Epoch 85, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.973145\n",
      "Epoch 86, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.974609\n",
      "Epoch 87, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.972656\n",
      "Epoch 88, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.976562\n",
      "Epoch 89, CIFAR-10 Batch 99:  Loss:     0.0000 Accuracy: 0.975098\n",
      "Epoch 90, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.974121\n",
      "Epoch 91, CIFAR-10 Batch 99:  Loss:     0.0000 Accuracy: 0.971680\n",
      "Epoch 92, CIFAR-10 Batch 99:  Loss:     0.0003 Accuracy: 0.975586\n",
      "Epoch 93, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.972656\n",
      "Epoch 94, CIFAR-10 Batch 99:  Loss:     0.0000 Accuracy: 0.972656\n",
      "Epoch 95, CIFAR-10 Batch 99:  Loss:     0.0002 Accuracy: 0.973145\n",
      "Epoch 96, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.972656\n",
      "Epoch 97, CIFAR-10 Batch 99:  Loss:     0.0000 Accuracy: 0.972168\n",
      "Epoch 98, CIFAR-10 Batch 99:  Loss:     0.0000 Accuracy: 0.977539\n",
      "Epoch 99, CIFAR-10 Batch 99:  Loss:     0.0000 Accuracy: 0.976074\n",
      "Epoch 100, CIFAR-10 Batch 99:  Loss:     0.0001 Accuracy: 0.976074\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    n_batches=100\n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        for batch_i in range(n_batches):\n",
    "            digits,targets=load_preprocess_training_batch(batch_i, batch_size)\n",
    "            train_neural_network(sess, optimizer, keep_probability,digits, targets)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, digits, targets, cost, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
